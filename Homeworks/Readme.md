| HW №                       | Dates                     | Type                        | Theme / Goal                                                                                                                | Format / Tasks                                                                    |
| -------------------------- | ------------------------- | --------------------------- | --------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| **[HW 1](./Homework1.md)** | Oct 04 → Oct 25 (3 weeks) | **Coding (Triton kernels)** | *Triton warm-ups*: implement a set of simple kernels (add, outer add, ReLU-mul, backward, sum, softmax, flash attention).   | 9 practical tasks with `torch.allclose` checks against PyTorch.                   |
| **[HW 2](./Homework2.md)** | Oct 06 → Oct 13 (1 week)  | **Theory test**             | *JIT & Compile in PyTorch 2.0*: JIT trace, JIT compile, `torch.compile` internals.                                          | 15 questions (multiple choice + short answer).                                    |
| **[HW 3](./Homework3.md)** | Oct 13 → Oct 20 (1 week)  | **Theory test**             | *Pruning & Sparsification + NAS*: overview of pruning/sparsification methods, motivation, sparsity types, and intro to NAS. | 15 questions (multiple choice + short answer).                                    |
| **[HW 4](./Homework4.md)** | Oct 20 → Nov 10 (3 weeks) | **Coding (Triton kernels)** | *Quantized Linear*: symmetric int8 quantization, forward (INT8 matmul + fused dequant), backward in Triton.                 | Implement `CustomLinearFunction` + `QuantizedLinear` class with forward/backward. |
